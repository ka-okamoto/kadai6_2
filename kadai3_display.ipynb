{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets,models,transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib import pylab as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanillaBackprop():\n",
    "   def __init__(self, model):\n",
    "     self.model = model\n",
    "     self.gradients = None\n",
    "     # Put model in evaluation mode\n",
    "     self.model.eval()\n",
    "     # Hook the first layer to get the gradient\n",
    "     self.hook_layers()\n",
    "\n",
    "   def hook_layers(self):\n",
    "     def hook_function(module, grad_in, grad_out):\n",
    "         print('grad_input: ',  grad_in[0].size())\n",
    "         print('grad_output: ', grad_out[0].size())\n",
    "         self.gradients = grad_in[0]\n",
    "             \n",
    "        \n",
    "     first_layer = list(self.model.features._modules.items())[0][1]\n",
    "     first_layer.register_backward_hook(hook_function)\n",
    "\n",
    "\n",
    "   def bpimage(self,tensor,Target_class):\n",
    "\n",
    "     out = self.model(tensor)\n",
    "     self.model.zero_grad()\n",
    "   \n",
    "     target = torch.zeros([1,out.size()[-1]],dtype=torch.float)\n",
    "     target[0][Target_class] = 1\n",
    "\n",
    "     out.backward(gradient=target)\n",
    "     gp=self.gradients.data.numpy()[0]\n",
    "     print(gp.shape)\n",
    "\n",
    "     return gp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(image):\n",
    "  normalize = transforms.Normalize(\n",
    "          mean =[0.485,0.456,0.406],\n",
    "          std = [0.229,0.224,0.225])\n",
    "\n",
    "  preprocess = transforms.Compose([\n",
    "          transforms.CenterCrop(224),\n",
    "          transforms.ToTensor(),\n",
    "          normalize])\n",
    "\n",
    "  img_tensor = preprocess(image)\n",
    "  img_tensor.unsqueeze_(0)#change 4D tensor\n",
    "  img_tensor.requires_grad_(requires_grad=True)\n",
    "   \n",
    "  return img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def afprocessing(npimg):\n",
    "  npimg = np.absolute(npimg)\n",
    "  npimg = npimg.transpose((2,1,0))\n",
    "  maxv = np.max(npimg)\n",
    "  npimg = npimg/maxv\n",
    "  print(npimg.shape)\n",
    "  return npimg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "def vg_img_show(image,vg):\n",
    "    \n",
    "     preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224)\n",
    "        ])\n",
    "     \n",
    "     fig=plt.figure()\n",
    "     ax1 = fig.add_subplot(1,2,1)\n",
    "     ax1.imshow(vg)\n",
    "\n",
    "     Img = preprocess(image)\n",
    "     Img = np.array(Img)\n",
    "     ax2 = fig.add_subplot(1,2,2)\n",
    "     ax2.grid(color='none')\n",
    "     ax2.imshow(Img)\n",
    "\n",
    "     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    " image = Image.open('/export/space/okamoto-ka/imgdata2/001.jpg')\n",
    " img_tensor = preprocessing(image)\n",
    " traget_num = 146\n",
    "\n",
    " vgg16 =models.vgg16(pretrained=True) \n",
    " bpi = VanillaBackprop(vgg16)\n",
    "\n",
    " vanilla_grads = bpi.bpimage(img_tensor,traget_num)\n",
    " n = afprocessing(vanilla_grads)\n",
    " np.save('vanilla_grads.npy',n) \n",
    " vanilla_grads=np.load('vanilla_grads.npy')\n",
    " vg_img_show(image,vanilla_grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Anaconda)",
   "language": "python",
   "name": "python3_anaconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
